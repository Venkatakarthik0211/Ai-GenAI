# ============================================================================
# Docker Environment Configuration for ML Pipeline
# ============================================================================
# This file contains docker-specific environment variables.
# Copy this to .env and fill in your AWS credentials:
#   cp .env.docker .env
#
# IMPORTANT: Never commit .env to version control!
# ============================================================================

# ============================================================================
# AWS CONFIGURATION (Required for Bedrock AI Agents)
# ============================================================================

# REQUIRED: Set your AWS credentials here
AWS_REGION=us-east-1
# AWS_ACCESS_KEY_ID=your_access_key_here
# AWS_SECRET_ACCESS_KEY=your_secret_key_here

# Alternatively, mount your ~/.aws directory (see docker-compose.yml)
# The compose file already mounts ${HOME}/.aws:/root/.aws:ro

# ============================================================================
# AWS BEDROCK CONFIGURATION
# ============================================================================

BEDROCK_MODEL_ID=anthropic.claude-3-sonnet-20240229-v1:0
BEDROCK_TEMPERATURE=0.0
BEDROCK_MAX_TOKENS=4096
BEDROCK_ENABLE_AGENTS=true
BEDROCK_TIMEOUT=60
BEDROCK_MAX_RETRIES=3

# ============================================================================
# MLFLOW CONFIGURATION
# ============================================================================

# MLflow is handled internally by docker-compose
# These are set automatically:
# MLFLOW_TRACKING_URI=http://mlflow:5000
# MLFLOW_BACKEND_STORE_URI=postgresql://mlflow:mlflow_password@postgres:5432/mlflow
# MLFLOW_ARTIFACT_ROOT=s3://mlflow-artifacts/

MLFLOW_EXPERIMENT_NAME=ml_pipeline_experiment
MLFLOW_ENABLE_LOGGING=true

# ============================================================================
# PIPELINE CONFIGURATION
# ============================================================================

# Data directory (inside container, host ./data/sample is mounted to /app/data/sample)
DATA_DIR=/app/data/sample

# Parallel execution (set to false for sequential on resource-constrained systems)
ENABLE_PARALLEL_TRAINING=true
MAX_PARALLEL_ALGORITHMS=2

# Monitoring and retraining
ENABLE_MONITORING=true
ENABLE_AUTO_RETRAIN=false

# ============================================================================
# PERFORMANCE TUNING FOR t3.2xlarge (8 vCPUs, 32GB RAM)
# ============================================================================

# Sequential execution mode (for resource-constrained scenarios)
# Uncomment these lines to run in sequential mode:
# ENABLE_PARALLEL_TRAINING=false
# MAX_PARALLEL_ALGORITHMS=1

# Worker concurrency (number of concurrent tasks per worker)
WORKER_CONCURRENCY=2

# GridSearchCV parallel jobs
# -1 uses all available cores, but can cause memory issues
# Recommended: 2-4 for t3.2xlarge
HYPERPARAMETER_SEARCH_JOBS=2

# Cross-validation folds (reduce if memory constrained)
CV_FOLDS=5

# ============================================================================
# OPTIONAL: Deployment Profiles
# ============================================================================

# Available profiles:
# - default: postgres, minio, mlflow, pipeline_backend, redis, worker_1
# - full: adds worker_2 for parallel execution
# - monitoring: adds flower dashboard

# To use profiles:
# docker-compose up -d                    # Default (single worker)
# docker-compose --profile full up -d     # Full (dual workers)
# docker-compose --profile monitoring up -d  # Add monitoring

# ============================================================================
# CONTAINER RESOURCE LIMITS (Already configured in docker-compose.yml)
# ============================================================================

# Default allocation for t3.2xlarge (8 vCPUs, 32GB RAM):
# - postgres: 1 vCPU, 2GB RAM
# - minio: 1 vCPU, 2GB RAM
# - mlflow: 2 vCPUs, 4GB RAM
# - pipeline_backend: 3 vCPUs, 8GB RAM
# - redis: 0.5 vCPU, 1GB RAM
# - worker_1: 2 vCPUs, 8GB RAM
# - worker_2 (optional): 2 vCPUs, 8GB RAM
#
# Total (default): ~9.5 vCPUs, 25GB RAM (leaves headroom for host)
# Total (full): ~11.5 vCPUs, 33GB RAM (slight overcommit, acceptable)

# ============================================================================
# STAGE 0: VERIFICATION MODE
# ============================================================================

# For Stage 0 testing, all containers will start with minimal configuration
# No actual pipeline execution, just health checks and API verification
