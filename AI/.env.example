# ============================================================================
# Enhanced ML Pipeline - Environment Configuration Template
# ============================================================================
# Copy this file to .env and fill in your values:
#   cp .env.example .env
#
# IMPORTANT: Never commit .env to version control!
# ============================================================================

# ============================================================================
# AWS CONFIGURATION (for Bedrock AI Agents)
# ============================================================================

# AWS Region where Bedrock is available
# Supported regions: us-east-1, us-west-2, eu-central-1, ap-southeast-1
AWS_REGION=us-east-1

# AWS Profile (if using AWS CLI credentials)
# Leave empty to use default profile
AWS_PROFILE=default

# AWS Credentials (Alternative to AWS CLI - use ONE method, not both)
# Only set these if NOT using AWS CLI profiles
# AWS_ACCESS_KEY_ID=your_access_key_here
# AWS_SECRET_ACCESS_KEY=your_secret_key_here

# ============================================================================
# AWS BEDROCK CONFIGURATION (AI Decision Agents)
# ============================================================================

# Bedrock Model ID for Claude
# Options:
#   - anthropic.claude-3-sonnet-20240229-v1:0 (Recommended - balanced performance)
#   - anthropic.claude-3-haiku-20240307-v1:0 (Faster, lower cost)
#   - anthropic.claude-3-opus-20240229-v1:0 (Most capable, higher cost)
BEDROCK_MODEL_ID=anthropic.claude-3-sonnet-20240229-v1:0

# Temperature for AI agent responses (0.0 = deterministic, 1.0 = creative)
BEDROCK_TEMPERATURE=0.0

# Maximum tokens for agent responses
BEDROCK_MAX_TOKENS=4096

# Enable/disable AI agents (true/false)
# If false, pipeline uses fallback logic instead of Bedrock agents
BEDROCK_ENABLE_AGENTS=true

# Agent timeout in seconds
BEDROCK_TIMEOUT=60

# Maximum retries for agent API calls
BEDROCK_MAX_RETRIES=3

# ============================================================================
# MLFLOW CONFIGURATION (Experiment Tracking)
# ============================================================================

# MLflow Tracking Server URI
# Local: http://localhost:5000
# Remote: http://your-mlflow-server:5000
MLFLOW_TRACKING_URI=http://localhost:5000

# MLflow Experiment Name (will be created if doesn't exist)
MLFLOW_EXPERIMENT_NAME=ml_pipeline_experiment

# Enable/disable MLflow logging (true/false)
# If false, results only saved to local outputs/ directory
MLFLOW_ENABLE_LOGGING=true

# Enable MLflow autologging (true/false)
MLFLOW_AUTOLOG=false

# MLflow Artifact Root
# Local: ./mlruns
# Production S3: s3://your-bucket/mlflow-artifacts
MLFLOW_ARTIFACT_ROOT=./mlruns

# Enable system metrics logging (CPU, GPU, memory)
MLFLOW_ENABLE_SYSTEM_METRICS_LOGGING=true

# Model Registry URI (optional, defaults to tracking URI)
# MLFLOW_REGISTRY_URI=http://localhost:5000

# ============================================================================
# PIPELINE CONFIGURATION
# ============================================================================

# Default data path (can be overridden via CLI)
DEFAULT_DATA_PATH=data/sample/netflix_titles_CLEANED.csv

# Default target column name
DEFAULT_TARGET_COLUMN=type

# Model type: classification or regression
DEFAULT_MODEL_TYPE=classification

# Output directory for artifacts
OUTPUT_DIR=outputs

# Random seed for reproducibility
RANDOM_SEED=42

# ============================================================================
# DATA PREPROCESSING CONFIGURATION
# ============================================================================

# Missing value threshold (drop columns with more missing than this)
MISSING_VALUE_THRESHOLD=0.5

# Scaling method: standard, minmax, robust, none
SCALING_METHOD=standard

# Encoding method: onehot, label, ordinal
ENCODING_METHOD=onehot

# Handle missing strategy: mean, median, mode, drop
MISSING_STRATEGY=mean

# ============================================================================
# FEATURE SELECTION CONFIGURATION
# ============================================================================

# Feature selection method: mutual_info, chi2, f_classif, f_regression
FEATURE_SELECTION_METHOD=mutual_info

# Number of features to select (0 = auto, -1 = all)
N_FEATURES_TO_SELECT=0

# Minimum feature importance threshold
MIN_FEATURE_IMPORTANCE=0.01

# ============================================================================
# MODEL TRAINING CONFIGURATION
# ============================================================================

# Train/test split ratio
TEST_SIZE=0.2

# Cross-validation folds
CV_FOLDS=5

# Cross-validation strategy: stratified, kfold, timeseries
CV_STRATEGY=stratified

# Stratify split by target (true/false)
STRATIFY_SPLIT=true

# ============================================================================
# HYPERPARAMETER TUNING CONFIGURATION
# ============================================================================

# Enable hyperparameter tuning (true/false)
ENABLE_TUNING=true

# Tuning method: grid, random, bayesian
TUNING_METHOD=grid

# Number of iterations for RandomizedSearchCV
N_ITER=10

# Number of parallel jobs (-1 = use all cores, 1 = sequential)
N_JOBS=-1

# Verbose level for tuning (0 = silent, 1 = minimal, 2 = detailed)
TUNING_VERBOSE=1

# Scoring metric for tuning
# Classification: accuracy, f1, roc_auc, precision, recall
# Regression: neg_mean_squared_error, neg_mean_absolute_error, r2
TUNING_SCORING=accuracy

# Cross-validation folds for GridSearchCV
GRID_SEARCH_CV_FOLDS=5

# ============================================================================
# MONITORING CONFIGURATION
# ============================================================================

# Enable performance monitoring (true/false)
ENABLE_MONITORING=true

# Drift detection method: ks_test, chi2, psi, all
DRIFT_DETECTION_METHOD=ks_test

# Drift threshold (0.0 - 1.0, higher = more drift detected)
DRIFT_THRESHOLD=0.1

# Performance drop threshold (percentage, e.g., 0.05 = 5% drop)
PERFORMANCE_DROP_THRESHOLD=0.05

# Monitor performance every N predictions
MONITORING_WINDOW_SIZE=1000

# Monitoring window in days
MONITORING_WINDOW_DAYS=30

# Alert on performance drop (true/false)
ALERT_ON_PERFORMANCE_DROP=true

# Alert on drift detection (true/false)
ALERT_ON_DRIFT=true

# ============================================================================
# RETRAINING CONFIGURATION
# ============================================================================

# Enable automated retraining (true/false)
ENABLE_AUTO_RETRAIN=true

# Retrain on drift detection (true/false)
AUTO_RETRAIN_ON_DRIFT=true

# Retrain on performance drop (true/false)
AUTO_RETRAIN_ON_PERFORMANCE_DROP=true

# Minimum new data size to trigger retraining
MIN_NEW_DATA_FOR_RETRAIN=100

# Retraining strategy: full, incremental
RETRAINING_STRATEGY=full

# Maximum retraining frequency (days)
MAX_RETRAIN_FREQUENCY_DAYS=30

# Optional: scheduled retraining interval in days
# RETRAIN_SCHEDULE_DAYS=30

# A/B test new model before deployment (true/false)
AB_TEST_NEW_MODEL=true

# A/B test sample percentage for new model
AB_TEST_PERCENTAGE=0.2

# ============================================================================
# ALGORITHM CONFIGURATION
# ============================================================================

# Algorithms to train (comma-separated, or "auto" to let agent decide)
# Classification: logistic_regression, random_forest, gradient_boosting, svm, knn
# Regression: linear_regression, ridge, lasso, random_forest_regressor, gradient_boosting_regressor
ALGORITHMS=auto

# Skip specific algorithms (comma-separated)
SKIP_ALGORITHMS=

# Maximum parallel algorithms to train simultaneously
MAX_PARALLEL_ALGORITHMS=3

# ============================================================================
# DECISION AGENT CONFIGURATION
# ============================================================================

# Cache agent responses to avoid repeated API calls (true/false)
AGENT_CACHE_RESPONSES=true

# Agent response timeout (seconds)
AGENT_RESPONSE_TIMEOUT=60

# Use fallback on agent failure (true/false)
AGENT_USE_FALLBACK=true

# ============================================================================
# COMPUTE & RESOURCE LIMITS
# ============================================================================

# Maximum memory per algorithm (GB, 0 = no limit)
MAX_MEMORY_GB=16

# Maximum training time per algorithm (minutes, 0 = no timeout)
MAX_TRAINING_TIME_MINUTES=60

# Enable GPU (true/false, requires GPU-enabled libraries)
ENABLE_GPU=false

# Enable parallel algorithm training (true/false)
ENABLE_PARALLEL_TRAINING=true

# ============================================================================
# LOGGING CONFIGURATION
# ============================================================================

# Logging level: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# Log file path
LOG_FILE=logs/pipeline.log

# Log format
LOG_FORMAT=%(asctime)s - %(name)s - %(levelname)s - %(message)s

# Enable console logging (true/false)
ENABLE_CONSOLE_LOGGING=true

# Enable file logging (true/false)
ENABLE_FILE_LOGGING=true

# ============================================================================
# ADVANCED CONFIGURATION
# ============================================================================

# Enable experiment caching (true/false)
ENABLE_CACHING=true

# Cache directory
CACHE_DIR=.cache

# Timeout per algorithm (seconds, 0 = no timeout)
ALGORITHM_TIMEOUT=0

# ============================================================================
# NOTIFICATION CONFIGURATION (Optional)
# ============================================================================

# Enable notifications (true/false)
ENABLE_NOTIFICATIONS=false

# Notification method: email, slack, webhook
NOTIFICATION_METHOD=email

# Email configuration (if using email notifications)
# SMTP_HOST=smtp.gmail.com
# SMTP_PORT=587
# SMTP_USER=your_email@gmail.com
# SMTP_PASSWORD=your_app_password
# EMAIL_RECIPIENTS=recipient1@example.com,recipient2@example.com

# Slack configuration (if using slack notifications)
# SLACK_WEBHOOK_URL=https://hooks.slack.com/services/YOUR/WEBHOOK/URL

# Webhook configuration (if using webhook notifications)
# WEBHOOK_URL=https://your-webhook-endpoint.com/notify

# ============================================================================
# PRODUCTION DEPLOYMENT CONFIGURATION (Optional)
# ============================================================================

# Model serving endpoint
# MODEL_SERVING_URL=http://localhost:8080

# Model deployment environment: development, staging, production
# DEPLOYMENT_ENV=development

# Model approval required (true/false)
# MODEL_APPROVAL_REQUIRED=true

# Gradual rollout percentage (0-100)
# GRADUAL_ROLLOUT_PERCENTAGE=10

# Rollback on error (true/false)
# AUTO_ROLLBACK=true

# ============================================================================
# END OF CONFIGURATION
# ============================================================================
