"""
Review Question Storage System - PostgreSQL with pgvector

Stores review questions generated by Agent 1 and user responses with vector embeddings:
1. PostgreSQL with pgvector - Structured querying, analytics, and vector similarity search
2. MLflow Artifacts - Experiment lineage and tracking

Uses sentence-transformers for generating embeddings to enable semantic similarity search.
"""

import json
import logging
from typing import Dict, Any, List, Optional
from datetime import datetime
import psycopg2
from psycopg2.extras import RealDictCursor
from pgvector.psycopg2 import register_vector
from sentence_transformers import SentenceTransformer

logger = logging.getLogger(__name__)


class ReviewStorageError(Exception):
    """Base exception for review storage errors"""
    pass


class ReviewStorage:
    """
    Storage system for review questions and user responses with vector embeddings.

    Provides unified interface for storing and querying review sessions:
    - PostgreSQL with pgvector (structured data + vector embeddings)
    - MLflow Artifacts (experiment tracking integration)

    Features:
    - Semantic similarity search using vector embeddings
    - Full-text search using PostgreSQL FTS
    - Analytics and aggregate queries
    """

    def __init__(
        self,
        postgres_connection_string: str,
        embedding_model_name: str = "sentence-transformers/all-MiniLM-L6-v2",
        mlflow_client: Optional[Any] = None,
        enable_embeddings: bool = False
    ):
        """
        Initialize review storage system.

        Args:
            postgres_connection_string: PostgreSQL connection string
            embedding_model_name: Sentence transformer model name (default: all-MiniLM-L6-v2, 384 dimensions)
            mlflow_client: MLflow client instance (optional)
            enable_embeddings: Enable vector embeddings (default: False to avoid slow model loading)
        """
        self.postgres_connection_string = postgres_connection_string
        self.mlflow_client = mlflow_client
        self.enable_embeddings = enable_embeddings
        self.embedding_model = None
        self.embedding_dim = None

        # Initialize PostgreSQL connection
        self._init_postgres()

        # Initialize embedding model only if enabled
        if enable_embeddings:
            self._init_embedding_model(embedding_model_name)
            logger.info(f"ReviewStorage initialized with embedding model: {embedding_model_name}")
        else:
            logger.info("ReviewStorage initialized without embeddings (faster startup)")

    def _init_postgres(self):
        """Initialize PostgreSQL connection with pgvector support"""
        try:
            self.postgres_conn = psycopg2.connect(self.postgres_connection_string)

            # Register pgvector type
            register_vector(self.postgres_conn)

            logger.info("PostgreSQL connection established with pgvector support")
        except psycopg2.Error as e:
            logger.error(f"Failed to connect to PostgreSQL: {e}")
            raise ReviewStorageError(f"PostgreSQL connection failed: {e}")

    def _init_embedding_model(self, model_name: str):
        """
        Initialize sentence transformer model for embeddings.

        Args:
            model_name: Sentence transformer model name
        """
        try:
            logger.info(f"Loading embedding model: {model_name}")
            self.embedding_model = SentenceTransformer(model_name)
            self.embedding_dim = self.embedding_model.get_sentence_embedding_dimension()
            logger.info(f"Embedding model loaded (dimension: {self.embedding_dim})")
        except Exception as e:
            logger.error(f"Failed to load embedding model: {e}")
            raise ReviewStorageError(f"Embedding model initialization failed: {e}")

    def generate_embedding(self, text: str) -> Optional[List[float]]:
        """
        Generate vector embedding for text.

        Returns None if embeddings are disabled.

        Args:
            text: Input text to embed

        Returns:
            List of floats representing the embedding vector or None
        """
        if not self.enable_embeddings or self.embedding_model is None:
            return None

        try:
            embedding = self.embedding_model.encode(text, convert_to_numpy=True)
            return embedding.tolist()
        except Exception as e:
            logger.error(f"Failed to generate embedding: {e}")
            raise ReviewStorageError(f"Embedding generation failed: {e}")

    def save_review_session(
        self,
        pipeline_run_id: str,
        questions: List[Dict[str, Any]],
        user_prompt: Optional[str] = None,
        extracted_config: Optional[Dict[str, Any]] = None,
        data_profile: Optional[Dict[str, Any]] = None,
        agent0_confidence: Optional[float] = None,
        mlflow_run_id: Optional[str] = None,
        mlflow_experiment_id: Optional[str] = None,
        bedrock_model_id: Optional[str] = None,
        bedrock_tokens_used: Optional[int] = None,
        question_generation_prompt: Optional[str] = None,
        bedrock_response: Optional[str] = None,
        generation_success: bool = True,
        error_message: Optional[str] = None
    ) -> int:
        """
        Save review session with questions to PostgreSQL and optionally to MLflow.

        Args:
            pipeline_run_id: Unique pipeline run identifier
            questions: List of question dictionaries
            user_prompt: Original user prompt from Agent 0
            extracted_config: Configuration extracted by Agent 0
            data_profile: Data profile from load_data node
            agent0_confidence: Agent 0 confidence score
            mlflow_run_id: MLflow run ID
            mlflow_experiment_id: MLflow experiment ID
            bedrock_model_id: Bedrock model ID used
            bedrock_tokens_used: Total tokens used
            question_generation_prompt: Prompt sent to Bedrock
            bedrock_response: Raw response from Bedrock
            generation_success: Whether generation succeeded
            error_message: Error message if generation failed

        Returns:
            PostgreSQL record ID (primary key)

        Raises:
            ReviewStorageError: If storage fails
        """
        logger.info(f"Saving review session for pipeline run: {pipeline_run_id}")

        timestamp = datetime.now()

        # Generate embedding for the question generation prompt or user prompt
        embedding_text = question_generation_prompt or user_prompt or ""
        embedding = self.generate_embedding(embedding_text) if embedding_text else None
        logger.debug(f"Generated embedding (dim={len(embedding) if embedding else 0})")

        # Extract total tokens from dictionary if needed
        total_tokens = None
        if bedrock_tokens_used:
            if isinstance(bedrock_tokens_used, dict):
                total_tokens = bedrock_tokens_used.get("total_tokens")
            elif isinstance(bedrock_tokens_used, int):
                total_tokens = bedrock_tokens_used

        # Prepare data for storage
        review_data = {
            "timestamp": timestamp,
            "pipeline_run_id": pipeline_run_id,
            "mlflow_run_id": mlflow_run_id,
            "mlflow_experiment_id": mlflow_experiment_id,
            "user_prompt": user_prompt,
            "extracted_config": json.dumps(extracted_config) if extracted_config else None,
            "data_profile": json.dumps(data_profile) if data_profile else None,
            "agent0_confidence": agent0_confidence,
            "questions": json.dumps(questions),
            "embedding": embedding,
            "bedrock_model_id": bedrock_model_id,
            "bedrock_tokens_used": total_tokens,
            "question_generation_prompt": question_generation_prompt,
            "bedrock_response": bedrock_response,
            "generation_success": generation_success,
            "error_message": error_message
        }

        # Storage 1: PostgreSQL with embedding
        review_id = self._save_to_postgres(review_data)
        logger.info(f"✓ Saved review session to PostgreSQL (ID: {review_id})")

        # Storage 2: MLflow Artifacts
        if self.mlflow_client and mlflow_run_id:
            try:
                self._save_to_mlflow(mlflow_run_id, review_data, questions)
                logger.info(f"✓ Saved to MLflow artifacts")
            except Exception as e:
                logger.warning(f"Failed to save to MLflow: {e} (continuing...)")
        else:
            logger.debug("MLflow storage skipped (no client or run_id)")

        logger.info(f"Review session saved successfully (ID: {review_id})")
        return review_id

    def save_algorithm_aware_review_session(
        self,
        pipeline_run_id: str,
        # Agent 1A outputs
        algorithm_category: str,
        algorithm_confidence: float,
        algorithm_requirements: Dict[str, Any],
        preprocessing_priorities: Dict[str, str],
        agent_1a_response: Dict[str, Any],
        # Agent 1B outputs
        questions: List[Dict[str, Any]],
        question_count: int,
        question_count_by_step: Dict[str, int],
        preprocessing_recommendations: Dict[str, Any],
        agent_1b_response: Dict[str, Any],
        # Metadata
        user_prompt: Optional[str] = None,
        data_profile: Optional[Dict[str, Any]] = None,
        mlflow_run_id: Optional[str] = None,
        bedrock_model_id: Optional[str] = None
    ) -> int:
        """
        Save algorithm-aware review session with Agent 1A and Agent 1B outputs to PostgreSQL.

        This method stores the two-agent HITL system outputs:
        - Agent 1A (AlgorithmCategoryPredictor): Algorithm category, confidence, requirements
        - Agent 1B (PreprocessingQuestionGenerator): Algorithm-aware preprocessing questions

        Args:
            pipeline_run_id: Unique pipeline run identifier
            algorithm_category: Predicted algorithm category (Agent 1A)
            algorithm_confidence: Confidence score (Agent 1A)
            algorithm_requirements: Algorithm requirements dict (Agent 1A)
            preprocessing_priorities: Preprocessing priorities dict (Agent 1A)
            agent_1a_response: Full Agent 1A response
            questions: List of generated questions (Agent 1B)
            question_count: Total number of questions (Agent 1B)
            question_count_by_step: Question count by preprocessing step (Agent 1B)
            preprocessing_recommendations: Preprocessing recommendations (Agent 1B)
            agent_1b_response: Full Agent 1B response
            user_prompt: Original user prompt
            data_profile: Data profile from load_data node
            mlflow_run_id: MLflow run ID
            bedrock_model_id: Bedrock model ID used

        Returns:
            PostgreSQL record ID (primary key)

        Raises:
            ReviewStorageError: If storage fails
        """
        logger.info(f"Saving algorithm-aware review session for pipeline run: {pipeline_run_id}")

        cursor = self.postgres_conn.cursor()

        try:
            # Note: This assumes the PostgreSQL schema has been updated with the new columns
            # If not, this will fail and we'll catch the error
            sql = """
                INSERT INTO review_questions (
                    pipeline_run_id,
                    session_id,
                    algorithm_category,
                    algorithm_confidence,
                    algorithm_requirements,
                    preprocessing_priorities,
                    agent_1a_response,
                    questions,
                    question_count,
                    question_count_by_step,
                    preprocessing_recommendations,
                    agent_1b_response,
                    user_prompt,
                    data_profile,
                    mlflow_run_id,
                    bedrock_model_id,
                    review_status,
                    created_at,
                    updated_at
                ) VALUES (
                    %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s
                )
                RETURNING id;
            """

            # Generate session_id (can be same as pipeline_run_id or UUID)
            session_id = pipeline_run_id
            timestamp = datetime.now()

            cursor.execute(sql, (
                pipeline_run_id,
                session_id,
                algorithm_category,
                algorithm_confidence,
                json.dumps(algorithm_requirements),
                json.dumps(preprocessing_priorities),
                json.dumps(agent_1a_response),
                json.dumps(questions),
                question_count,
                json.dumps(question_count_by_step),
                json.dumps(preprocessing_recommendations),
                json.dumps(agent_1b_response),
                user_prompt,
                json.dumps(data_profile) if data_profile else None,
                mlflow_run_id,
                bedrock_model_id,
                'awaiting_review',
                timestamp,
                timestamp
            ))

            review_id = cursor.fetchone()[0]
            self.postgres_conn.commit()
            cursor.close()

            logger.info(f"✓ Saved algorithm-aware review session to PostgreSQL (ID: {review_id})")
            return review_id

        except psycopg2.Error as e:
            self.postgres_conn.rollback()
            cursor.close()
            logger.error(f"PostgreSQL insert failed: {e}")
            logger.warning(
                "This may be due to missing columns in the review_questions table. "
                "Ensure the PostgreSQL schema has been updated for algorithm-aware reviews."
            )
            raise ReviewStorageError(f"Failed to save algorithm-aware review session: {e}")

    def _save_to_postgres(self, review_data: Dict[str, Any]) -> int:
        """
        Save review session to PostgreSQL database with vector embedding.

        Args:
            review_data: Dictionary with review data

        Returns:
            PostgreSQL record ID
        """
        cursor = self.postgres_conn.cursor()

        try:
            sql = """
                INSERT INTO review_questions (
                    timestamp, pipeline_run_id, mlflow_run_id, mlflow_experiment_id,
                    user_prompt, extracted_config, data_profile, agent0_confidence,
                    questions, embedding, bedrock_model_id, bedrock_tokens_used,
                    question_generation_prompt, bedrock_response, generation_success, error_message
                ) VALUES (
                    %(timestamp)s, %(pipeline_run_id)s, %(mlflow_run_id)s, %(mlflow_experiment_id)s,
                    %(user_prompt)s, %(extracted_config)s, %(data_profile)s, %(agent0_confidence)s,
                    %(questions)s, %(embedding)s, %(bedrock_model_id)s, %(bedrock_tokens_used)s,
                    %(question_generation_prompt)s, %(bedrock_response)s, %(generation_success)s, %(error_message)s
                )
                RETURNING id;
            """

            cursor.execute(sql, review_data)
            review_id = cursor.fetchone()[0]

            self.postgres_conn.commit()
            cursor.close()

            return review_id

        except psycopg2.Error as e:
            self.postgres_conn.rollback()
            cursor.close()
            logger.error(f"PostgreSQL insert failed: {e}")
            raise ReviewStorageError(f"Failed to save to PostgreSQL: {e}")

    def _save_to_mlflow(self, mlflow_run_id: str, review_data: Dict[str, Any], questions: List[Dict[str, Any]]):
        """
        Save review questions to MLflow artifacts.

        Args:
            mlflow_run_id: MLflow run ID
            review_data: Dictionary with review data
            questions: List of questions
        """
        if not self.mlflow_client:
            return

        try:
            import mlflow
            import tempfile
            import os

            # Create temporary directory for artifacts
            with tempfile.TemporaryDirectory() as tmpdir:
                # Save questions
                questions_path = os.path.join(tmpdir, "review_questions.json")
                with open(questions_path, 'w') as f:
                    json.dump(questions, f, indent=2)

                # Save question generation prompt
                if review_data.get("question_generation_prompt"):
                    prompt_path = os.path.join(tmpdir, "question_generation_prompt.txt")
                    with open(prompt_path, 'w') as f:
                        f.write(review_data["question_generation_prompt"])

                # Save full review data (excluding embedding for space efficiency)
                full_data_path = os.path.join(tmpdir, "review_data.json")
                data_copy = {k: v for k, v in review_data.items() if k != 'embedding'}
                data_copy["timestamp"] = data_copy["timestamp"].isoformat()
                with open(full_data_path, 'w') as f:
                    json.dump(data_copy, f, indent=2)

                # Log artifacts to MLflow
                with mlflow.start_run(run_id=mlflow_run_id):
                    mlflow.log_artifact(questions_path, artifact_path="review")
                    if review_data.get("question_generation_prompt"):
                        mlflow.log_artifact(prompt_path, artifact_path="review")
                    mlflow.log_artifact(full_data_path, artifact_path="review")

        except Exception as e:
            logger.error(f"MLflow artifact logging failed: {e}")
            raise ReviewStorageError(f"Failed to save to MLflow: {e}")

    def update_review_answers(
        self,
        pipeline_run_id: str,
        answers: List[Dict[str, Any]],
        review_status: str = "completed",
        approved: Optional[bool] = None,
        user_feedback: Optional[str] = None
    ) -> bool:
        """
        Update review session with user answers.

        Args:
            pipeline_run_id: Pipeline run identifier
            answers: List of answer dictionaries
            review_status: Status (pending, approved, rejected, modified)
            approved: Whether user approved
            user_feedback: Optional feedback

        Returns:
            True if successful

        Raises:
            ReviewStorageError: If update fails
        """
        cursor = self.postgres_conn.cursor()

        try:
            sql = """
                UPDATE review_questions
                SET answers = %s,
                    review_status = %s,
                    approved = %s,
                    user_feedback = %s,
                    answered_at = %s
                WHERE pipeline_run_id = %s;
            """

            cursor.execute(sql, (
                json.dumps(answers),
                review_status,
                approved,
                user_feedback,
                datetime.now(),
                pipeline_run_id
            ))

            self.postgres_conn.commit()
            cursor.close()

            logger.info(f"Updated review answers for run: {pipeline_run_id}")
            return True

        except psycopg2.Error as e:
            self.postgres_conn.rollback()
            cursor.close()
            logger.error(f"PostgreSQL update failed: {e}")
            raise ReviewStorageError(f"Failed to update answers: {e}")

    def get_review_by_run_id(self, pipeline_run_id: str) -> Optional[Dict[str, Any]]:
        """
        Retrieve review session by pipeline run ID.

        Args:
            pipeline_run_id: Pipeline run identifier

        Returns:
            Dictionary with review data or None if not found
        """
        cursor = self.postgres_conn.cursor(cursor_factory=RealDictCursor)

        try:
            sql = """
                SELECT * FROM review_questions
                WHERE pipeline_run_id = %s;
            """
            cursor.execute(sql, (pipeline_run_id,))
            result = cursor.fetchone()
            cursor.close()

            if result:
                return dict(result)
            return None

        except psycopg2.Error as e:
            cursor.close()
            logger.error(f"PostgreSQL query failed: {e}")
            raise ReviewStorageError(f"Failed to retrieve review: {e}")

    def get_pending_reviews(self, limit: int = 10) -> List[Dict[str, Any]]:
        """
        Get all pending review sessions.

        Args:
            limit: Maximum number of results

        Returns:
            List of dictionaries with review data
        """
        cursor = self.postgres_conn.cursor(cursor_factory=RealDictCursor)

        try:
            sql = """
                SELECT * FROM review_questions
                WHERE review_status = 'pending'
                ORDER BY timestamp DESC
                LIMIT %s;
            """
            cursor.execute(sql, (limit,))
            results = cursor.fetchall()
            cursor.close()

            return [dict(row) for row in results]

        except psycopg2.Error as e:
            cursor.close()
            logger.error(f"PostgreSQL query failed: {e}")
            raise ReviewStorageError(f"Failed to query pending reviews: {e}")

    def get_analytics_summary(self) -> Dict[str, Any]:
        """
        Get analytics summary of review sessions.

        Returns:
            Dictionary with aggregate statistics
        """
        cursor = self.postgres_conn.cursor(cursor_factory=RealDictCursor)

        try:
            # Total reviews and approval rate
            cursor.execute("""
                SELECT
                    COUNT(*) AS total_reviews,
                    SUM(CASE WHEN approved = TRUE THEN 1 ELSE 0 END) AS approved_count,
                    SUM(CASE WHEN approved = FALSE THEN 1 ELSE 0 END) AS rejected_count,
                    SUM(CASE WHEN review_status = 'pending' THEN 1 ELSE 0 END) AS pending_count,
                    AVG(CASE WHEN agent0_confidence IS NOT NULL THEN agent0_confidence ELSE NULL END) AS avg_agent0_confidence
                FROM review_questions;
            """)
            overall_stats = dict(cursor.fetchone())

            # Approval rate by analysis type
            cursor.execute("""
                SELECT
                    extracted_config->>'analysis_type' AS analysis_type,
                    COUNT(*) AS total,
                    SUM(CASE WHEN approved = TRUE THEN 1 ELSE 0 END) AS approved,
                    ROUND(100.0 * SUM(CASE WHEN approved = TRUE THEN 1 ELSE 0 END) / COUNT(*), 2) AS approval_rate
                FROM review_questions
                WHERE review_status != 'pending'
                GROUP BY extracted_config->>'analysis_type';
            """)
            by_analysis_type = [dict(row) for row in cursor.fetchall()]

            # Recent rejections
            cursor.execute("""
                SELECT
                    timestamp,
                    user_prompt,
                    user_feedback,
                    agent0_confidence
                FROM review_questions
                WHERE approved = FALSE
                ORDER BY timestamp DESC
                LIMIT 5;
            """)
            recent_rejections = [dict(row) for row in cursor.fetchall()]

            cursor.close()

            return {
                "overall": overall_stats,
                "by_analysis_type": by_analysis_type,
                "recent_rejections": recent_rejections
            }

        except psycopg2.Error as e:
            cursor.close()
            logger.error(f"Analytics query failed: {e}")
            raise ReviewStorageError(f"Failed to get analytics: {e}")

    def close(self):
        """Close database connections"""
        if self.postgres_conn:
            self.postgres_conn.close()
            logger.info("PostgreSQL connection closed")


def create_review_storage_from_env() -> ReviewStorage:
    """
    Create ReviewStorage instance from environment variables.

    Expected environment variables:
    - POSTGRES_HOST (default: localhost)
    - POSTGRES_PORT (default: 5432)
    - POSTGRES_DB (default: ml_pipeline)
    - POSTGRES_USER (required)
    - POSTGRES_PASSWORD (required)
    - EMBEDDING_MODEL (default: sentence-transformers/all-MiniLM-L6-v2)

    Returns:
        Configured ReviewStorage instance
    """
    import os

    # Build PostgreSQL connection string
    postgres_host = os.getenv('POSTGRES_HOST', 'localhost')
    postgres_port = os.getenv('POSTGRES_PORT', '5432')
    postgres_db = os.getenv('POSTGRES_DB', 'ml_pipeline')
    postgres_user = os.getenv('POSTGRES_USER')
    postgres_password = os.getenv('POSTGRES_PASSWORD')

    if not postgres_user or not postgres_password:
        raise ValueError("POSTGRES_USER and POSTGRES_PASSWORD environment variables are required")

    postgres_connection_string = (
        f"postgresql://{postgres_user}:{postgres_password}@"
        f"{postgres_host}:{postgres_port}/{postgres_db}"
    )

    # Get embedding model configuration
    embedding_model = os.getenv('EMBEDDING_MODEL', 'sentence-transformers/all-MiniLM-L6-v2')
    enable_embeddings = os.getenv('ENABLE_EMBEDDINGS', 'false').lower() == 'true'

    return ReviewStorage(
        postgres_connection_string=postgres_connection_string,
        embedding_model_name=embedding_model,
        enable_embeddings=enable_embeddings
    )
